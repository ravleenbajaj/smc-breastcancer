{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Annealed SMC for Breast Cancer Classification\"\n",
        "author: \"Your Name\"\n",
        "format:\n",
        "  html:\n",
        "    code-fold: false\n",
        "    toc: true\n",
        "    theme: cosmo\n",
        "jupyter: julia-1.11\n",
        "---\n",
        "\n",
        "# Annealed Sequential Monte Carlo for Bayesian Logistic Regression\n",
        "\n",
        "This analysis applies Annealed Sequential Monte Carlo (SMC) to perform Bayesian inference on the Wisconsin Breast Cancer dataset. We estimate posterior distributions for logistic regression coefficients that predict malignant vs benign tumors.\n",
        "\n",
        "## Setup"
      ],
      "id": "0bddb0ef"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import Pkg\n",
        "Pkg.add([\"CSV\", \"DataFrames\", \"Printf\", \"Plots\", \"StatsBase\", \"HTTP\", \"Distributions\"])\n",
        "\n",
        "include(\"dataset.jl\")\n",
        "include(\"smc.jl\")\n",
        "\n",
        "using .SMC\n",
        "using Random\n",
        "using Plots\n",
        "using StatsBase\n",
        "using Statistics\n",
        "using DataFrames\n",
        "using Printf\n",
        "\n",
        "Random.seed!(42)"
      ],
      "id": "a314d643",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load and Explore Data"
      ],
      "id": "c211b291"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: load-data\n",
        "\n",
        "# Load the breast cancer dataset\n",
        "X, y = load_breast_cancer()\n",
        "\n",
        "println(\"Dataset dimensions: $(size(X))\")\n",
        "println(\"Number of features: $(size(X, 2))\")\n",
        "println(\"Number of samples: $(size(X, 1))\")\n",
        "println(\"\\nClass distribution:\")\n",
        "println(\"  Benign (0): $(sum(y .== 0))\")\n",
        "println(\"  Malignant (1): $(sum(y .== 1))\")"
      ],
      "id": "load-data",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: data-summary\n",
        "\n",
        "# Feature statistics\n",
        "feature_names = [\"Clump Thickness\", \"Uniformity Cell Size\", \"Uniformity Cell Shape\",\n",
        "                 \"Marginal Adhesion\", \"Single Epithelial Cell Size\", \"Bare Nuclei\",\n",
        "                 \"Bland Chromatin\", \"Normal Nucleoli\", \"Mitoses\"]\n",
        "\n",
        "df_summary = DataFrame(\n",
        "    Feature = feature_names,\n",
        "    Mean = vec(mean(X, dims=1)),\n",
        "    Std = vec(std(X, dims=1)),\n",
        "    Min = vec(minimum(X, dims=1)),\n",
        "    Max = vec(maximum(X, dims=1))\n",
        ")\n",
        "\n",
        "println(\"\\nFeature Summary Statistics:\")\n",
        "show(df_summary, allrows=true)"
      ],
      "id": "data-summary",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run Annealed SMC\n",
        "\n",
        "We use Sequential Monte Carlo with annealing to sample from the posterior distribution of logistic regression coefficients. The algorithm gradually transitions from the prior (β=0) to the posterior (β=1)."
      ],
      "id": "3debfc2c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: run-smc\n",
        "\n",
        "# SMC hyperparameters\n",
        "N_particles = 500\n",
        "mcmc_steps = 5\n",
        "step_scale = 0.05\n",
        "ess_threshold = 0.5\n",
        "\n",
        "println(\"\\nRunning Annealed SMC...\")\n",
        "println(\"  Particles: $N_particles\")\n",
        "println(\"  MCMC steps per iteration: $mcmc_steps\")\n",
        "println(\"  Step scale: $step_scale\")\n",
        "println(\"  ESS threshold: $ess_threshold\")\n",
        "\n",
        "# Run the sampler\n",
        "@time particles, particle_weights, betas, acc_hist = SMC.annealed_smc(\n",
        "    X, y;\n",
        "    N=N_particles,\n",
        "    mcmc_steps=mcmc_steps,\n",
        "    step_scale=step_scale,\n",
        "    ess_frac=ess_threshold\n",
        ")\n",
        "\n",
        "println(\"\\nSMC completed!\")\n",
        "println(\"  Total annealing steps: $(length(betas))\")\n",
        "println(\"  Final β: $(betas[end])\")\n",
        "println(\"  Mean acceptance rate: $(round(mean(acc_hist), digits=3))\")"
      ],
      "id": "run-smc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Annealing Schedule"
      ],
      "id": "0054d671"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: plot-annealing\n",
        "#| fig-cap: Annealing schedule showing the progression of temperature parameter β from 0 (prior) to 1 (posterior)\n",
        "\n",
        "plot(1:length(betas), betas,\n",
        "     xlabel=\"Iteration\",\n",
        "     ylabel=\"β (Temperature)\",\n",
        "     title=\"Annealing Schedule\",\n",
        "     legend=false,\n",
        "     linewidth=2,\n",
        "     marker=:circle,\n",
        "     markersize=3,\n",
        "     grid=true)\n",
        "hline!([0.0, 1.0], linestyle=:dash, color=:gray, alpha=0.5)"
      ],
      "id": "plot-annealing",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The annealing schedule adaptively chooses temperature increments to maintain effective sample size (ESS) above the threshold.\n",
        "\n",
        "## MCMC Acceptance Rate"
      ],
      "id": "5427f97b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: plot-acceptance\n",
        "#| fig-cap: Metropolis-Hastings acceptance rates throughout the annealing process\n",
        "\n",
        "plot(1:length(acc_hist), acc_hist,\n",
        "     xlabel=\"Iteration\",\n",
        "     ylabel=\"Acceptance Rate\",\n",
        "     title=\"MCMC Acceptance Rate per Iteration\",\n",
        "     legend=false,\n",
        "     linewidth=2,\n",
        "     color=:green,\n",
        "     grid=true,\n",
        "     ylim=(0, 1))\n",
        "hline!([0.234], linestyle=:dash, color=:red, \n",
        "       label=\"Optimal (0.234)\", alpha=0.5)"
      ],
      "id": "plot-acceptance",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Acceptance rates around 0.2-0.4 indicate good mixing in the MCMC moves.\n",
        "\n",
        "## Posterior Analysis\n",
        "\n",
        "### Posterior Mean Estimates"
      ],
      "id": "9d61982e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: posterior-mean\n",
        "\n",
        "# Define feature names\n",
        "feature_names = [\"Cl.thickness\", \"Cell.size\", \"Cell.shape\", \n",
        "                 \"Marg.adhesion\", \"Epith.c.size\", \"Bare.nuclei\",\n",
        "                 \"Bl.cromatin\", \"Normal.nucleoli\", \"Mitoses\"]\n",
        "\n",
        "# Compute weighted posterior statistics\n",
        "posterior_mean = vec(sum(particles .* particle_weights, dims=1))\n",
        "posterior_var = vec(sum((particles .- posterior_mean').^2 .* particle_weights, dims=1))\n",
        "posterior_std = sqrt.(posterior_var)\n",
        "\n",
        "df_posterior = DataFrame(\n",
        "    Feature = feature_names,\n",
        "    Mean = posterior_mean,\n",
        "    Std = posterior_std,\n",
        "    Lower_95 = posterior_mean .- 1.96 .* posterior_std,\n",
        "    Upper_95 = posterior_mean .+ 1.96 .* posterior_std\n",
        ")\n",
        "\n",
        "println(\"\\nPosterior Summary:\")\n",
        "show(df_posterior, allrows=true)"
      ],
      "id": "posterior-mean",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Interpretation\n",
        "\n",
        "Positive coefficients increase the log-odds of malignancy:"
      ],
      "id": "5193e906"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: significant-features\n",
        "\n",
        "# Identify \"significant\" features (95% CI excludes zero)\n",
        "significant = (df_posterior.Lower_95 .> 0) .| (df_posterior.Upper_95 .< 0)\n",
        "\n",
        "println(\"\\nFeatures with credible intervals excluding zero:\")\n",
        "for (i, feat) in enumerate(feature_names)\n",
        "    if significant[i]\n",
        "        direction = posterior_mean[i] > 0 ? \"increases\" : \"decreases\"\n",
        "        println(\"  • $feat: $(direction) malignancy risk\")\n",
        "        println(\"    Coefficient: $(round(posterior_mean[i], digits=3)) ± $(round(posterior_std[i], digits=3))\")\n",
        "    end\n",
        "end"
      ],
      "id": "significant-features",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Posterior Distributions\n",
        "\n",
        "### Coefficient Posterior Densities"
      ],
      "id": "5ae7f38d"
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig-width": 10,
        "fig-height": 12
      },
      "source": [
        "#| label: plot-posteriors\n",
        "#| fig-cap: Posterior distributions for each logistic regression coefficient\n",
        "\n",
        "# Create subplots for each coefficient\n",
        "plots_array = []\n",
        "\n",
        "for (i, feat) in enumerate(feature_names)\n",
        "    # Get samples for this feature\n",
        "    samples = particles[:, i]\n",
        "    \n",
        "    # Create weighted histogram\n",
        "    p = histogram(samples, weights=particle_weights,\n",
        "                 bins=30,\n",
        "                 normalize=:pdf,\n",
        "                 xlabel=\"Coefficient Value\",\n",
        "                 ylabel=\"Density\",\n",
        "                 title=feat,\n",
        "                 legend=false,\n",
        "                 alpha=0.7,\n",
        "                 color=:steelblue)\n",
        "    \n",
        "    # Add posterior mean\n",
        "    vline!([posterior_mean[i]], \n",
        "           linewidth=2, \n",
        "           color=:red, \n",
        "           linestyle=:solid)\n",
        "    \n",
        "    # Add credible interval\n",
        "    vline!([df_posterior.Lower_95[i], df_posterior.Upper_95[i]], \n",
        "           linewidth=1.5, \n",
        "           color=:orange, \n",
        "           linestyle=:dash)\n",
        "    \n",
        "    # Add zero line\n",
        "    vline!([0], linewidth=1, color=:gray, linestyle=:dot)\n",
        "    \n",
        "    push!(plots_array, p)\n",
        "end\n",
        "\n",
        "plot(plots_array..., layout=(5, 2), size=(1000, 1200))"
      ],
      "id": "plot-posteriors",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Top Features by Effect Size"
      ],
      "id": "75581051"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: top-features\n",
        "\n",
        "# Rank features by absolute posterior mean\n",
        "effect_sizes = abs.(posterior_mean)\n",
        "ranked_idx = sortperm(effect_sizes, rev=true)\n",
        "\n",
        "println(\"\\nTop 5 Features by Effect Size:\")\n",
        "for (rank, idx) in enumerate(ranked_idx[1:5])\n",
        "    println(\"$rank. $(feature_names[idx])\")\n",
        "    println(\"   Coefficient: $(round(posterior_mean[idx], digits=3))\")\n",
        "    println(\"   Std Dev: $(round(posterior_std[idx], digits=3))\")\n",
        "    println(\"   95% CI: [$(round(df_posterior.Lower_95[idx], digits=3)), $(round(df_posterior.Upper_95[idx], digits=3))]\")\n",
        "    println()\n",
        "end"
      ],
      "id": "top-features",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Particle Cloud Visualization"
      ],
      "id": "c2089f43"
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig-width": 8,
        "fig-height": 6
      },
      "source": [
        "#| label: particle-pairs\n",
        "#| fig-cap: Particle cloud showing joint posterior for top two features\n",
        "\n",
        "# Plot top 2 features\n",
        "idx1, idx2 = ranked_idx[1:2]\n",
        "\n",
        "scatter(particles[:, idx1], particles[:, idx2],\n",
        "        markersize=weights .* length(weights) .* 3,\n",
        "        alpha=0.5,\n",
        "        xlabel=feature_names[idx1],\n",
        "        ylabel=feature_names[idx2],\n",
        "        title=\"Joint Posterior: Top 2 Features\",\n",
        "        legend=false,\n",
        "        color=:steelblue)\n",
        "\n",
        "# Add posterior means\n",
        "scatter!([posterior_mean[idx1]], [posterior_mean[idx2]],\n",
        "         markersize=10,\n",
        "         color=:red,\n",
        "         marker=:star,\n",
        "         label=\"Posterior Mean\")"
      ],
      "id": "particle-pairs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Diagnostics\n",
        "\n",
        "### Effective Sample Size History"
      ],
      "id": "aa0b13fd"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: ess-diagnostic\n",
        "\n",
        "# Compute ESS at each iteration (approximate from acceptance rates)\n",
        "println(\"\\nEffective Sample Size Diagnostics:\")\n",
        "println(\"  Number of particles: $N_particles\")\n",
        "println(\"  ESS threshold: $(ess_threshold * N_particles)\")\n",
        "println(\"  Resampling triggered: $(length(betas) - 1) times\")"
      ],
      "id": "ess-diagnostic",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Particle Weight Distribution"
      ],
      "id": "7d1618f0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: weight-distribution\n",
        "#| fig-cap: Distribution of final particle weights\n",
        "\n",
        "histogram(particle_weights,\n",
        "          bins=30,\n",
        "          xlabel=\"Weight\",\n",
        "          ylabel=\"Frequency\",\n",
        "          title=\"Final Particle Weight Distribution\",\n",
        "          legend=false,\n",
        "          color=:purple,\n",
        "          alpha=0.7)\n",
        "\n",
        "# Add ESS calculation\n",
        "final_ess = 1 / sum(particle_weights.^2)\n",
        "println(\"\\nFinal Effective Sample Size: $(round(final_ess, digits=1))\")\n",
        "println(\"ESS / N: $(round(final_ess / N_particles, digits=3))\")"
      ],
      "id": "weight-distribution",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Predictive Performance"
      ],
      "id": "665584a7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: predictions\n",
        "\n",
        "# Make predictions using posterior mean\n",
        "X_with_intercept = hcat(ones(size(X, 1)), X)\n",
        "# Note: If your features don't include intercept, adjust accordingly\n",
        "\n",
        "# For simplicity, use posterior mean coefficients\n",
        "eta = X * posterior_mean\n",
        "probs = 1 ./ (1 .+ exp.(-eta))\n",
        "y_pred = Float64.(probs .> 0.5)\n",
        "\n",
        "# Compute accuracy\n",
        "accuracy = mean(y_pred .== y)\n",
        "println(\"\\nPredictive Performance (Posterior Mean):\")\n",
        "println(\"  Accuracy: $(round(accuracy * 100, digits=2))%\")\n",
        "\n",
        "# Confusion matrix\n",
        "tp = sum((y_pred .== 1) .& (y .== 1))\n",
        "tn = sum((y_pred .== 0) .& (y .== 0))\n",
        "fp = sum((y_pred .== 1) .& (y .== 0))\n",
        "fn = sum((y_pred .== 0) .& (y .== 1))\n",
        "\n",
        "println(\"\\nConfusion Matrix:\")\n",
        "println(\"              Predicted\")\n",
        "println(\"              Neg    Pos\")\n",
        "println(\"Actual Neg    $tn     $fp\")\n",
        "println(\"       Pos    $fn     $tp\")\n",
        "\n",
        "# Metrics\n",
        "sensitivity = tp / (tp + fn)\n",
        "specificity = tn / (tn + fp)\n",
        "precision = tp / (tp + fp)\n",
        "\n",
        "println(\"\\nMetrics:\")\n",
        "println(\"  Sensitivity (Recall): $(round(sensitivity, digits=3))\")\n",
        "println(\"  Specificity: $(round(specificity, digits=3))\")\n",
        "println(\"  Precision: $(round(precision, digits=3))\")"
      ],
      "id": "predictions",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This analysis demonstrated Bayesian logistic regression using Annealed Sequential Monte Carlo on the Wisconsin Breast Cancer dataset. Key findings:\n",
        "\n",
        "1. **Annealing Schedule**: The adaptive temperature schedule required $(length(betas)) iterations to transition from prior to posterior.\n",
        "\n",
        "2. **Key Predictive Features**: The features with strongest effects are shown above, with credible intervals excluding zero indicating statistical significance in the Bayesian sense.\n",
        "\n",
        "3. **Model Performance**: The posterior mean classifier achieves $(round(accuracy * 100, digits=1))% accuracy on the training data.\n",
        "\n",
        "4. **Posterior Uncertainty**: The posterior distributions show varying degrees of uncertainty across features, with some coefficients more precisely estimated than others.\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "- **Cross-validation**: Implement k-fold CV to assess out-of-sample performance\n",
        "- **Model comparison**: Compare with simpler models using marginal likelihood\n",
        "- **Feature selection**: Use posterior distributions to identify sparse models\n",
        "- **Sensitivity analysis**: Test robustness to prior specifications"
      ],
      "id": "b3cb8ea3"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "julia-1.11",
      "language": "julia",
      "display_name": "Julia 1.11.5",
      "path": "/Users/ravleenbajaj/Library/Jupyter/kernels/julia-1.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}